{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28db09d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Combined alerts saved to 'combined_disruption_alerts.json'\n",
      "\n",
      "ðŸš¨ Protest @ (13.085, 80.2101)\n",
      "  â†’ Protest happening near Anna Nagar causing road closures\n",
      "\n",
      "ðŸš¨ Construction @ (12.8956, 80.2267)\n",
      "  â†’ Construction work on OMR causing major delays.\n",
      "\n",
      "ðŸš¨ Road Closure @ (13.0569, 80.2412)\n",
      "  â†’ Emergency vehicles blocking Mount Road. Traffic moving slowly\n",
      "\n",
      "ðŸš¨ Low Traffic Speed @ (13.0418, 80.2341)\n",
      "  â†’ Predicted slow traffic on nungambakkam - t.nagar (6.9 km/h)\n",
      "\n",
      "ðŸš¨ Low Traffic Speed @ (13.045, 80.215)\n",
      "  â†’ Predicted slow traffic on anna nagar - adyar (8.5 km/h)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from transformers import pipeline\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# --------------------- Twitter NLP Disruption Detection --------------------- #\n",
    "\n",
    "class TwitterNLPModel:\n",
    "    def __init__(self):\n",
    "        self.classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "        self.disruption_labels = [\"protest\", \"accident\", \"road closure\", \"traffic jam\", \"construction\", \"emergency\", \"normal\"]\n",
    "        self.mock_locations = {\n",
    "            'nungambakkam': (13.0569, 80.2412),\n",
    "            'anna nagar': (13.0850, 80.2101),\n",
    "            't nagar': (13.0418, 80.2341),\n",
    "            'adyar': (13.0067, 80.2206),\n",
    "            'velachery': (12.9816, 80.2209),\n",
    "            'tambaram': (12.9249, 80.1000),\n",
    "            'chrompet': (12.9516, 80.1462),\n",
    "            'omr': (12.8956, 80.2267),\n",
    "            'ecr': (12.8270, 80.2420),\n",
    "            'mount road': (13.0569, 80.2412),\n",
    "            'velachery junction': (12.9800, 80.2210)\n",
    "        }\n",
    "\n",
    "    def preprocess_tweet(self, text: str) -> str:\n",
    "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "        text = re.sub(r\"@\\w+\", '', text)\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def classify_event(self, text: str) -> Dict:\n",
    "        try:\n",
    "            result = self.classifier(text, self.disruption_labels)\n",
    "            return {\n",
    "                \"label\": result[\"labels\"][0],\n",
    "                \"confidence\": result[\"scores\"][0],\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Classification error: {e}\")\n",
    "            return {\"label\": \"normal\", \"confidence\": 0.0}\n",
    "\n",
    "    def extract_location(self, text: str) -> Optional[Tuple[str, Tuple[float, float]]]:\n",
    "        text = text.lower()\n",
    "        for loc in self.mock_locations:\n",
    "            if loc in text:\n",
    "                return loc.title(), self.mock_locations[loc]\n",
    "        return None\n",
    "\n",
    "    def get_mock_tweets(self) -> List[Dict]:\n",
    "        return [\n",
    "            {'id': '1', 'text': 'Heavy traffic jam at Nungambakkam area due to accident.', 'created_at': datetime.now()},\n",
    "            {'id': '2', 'text': 'Protest happening near Anna Nagar causing road closures', 'created_at': datetime.now() - timedelta(minutes=15)},\n",
    "            {'id': '3', 'text': 'Construction work on OMR causing major delays.', 'created_at': datetime.now() - timedelta(minutes=30)},\n",
    "            {'id': '4', 'text': 'Emergency vehicles blocking Mount Road. Traffic moving slowly', 'created_at': datetime.now() - timedelta(minutes=45)},\n",
    "            {'id': '5', 'text': 'Water logging at Velachery junction after rain. Roads flooded', 'created_at': datetime.now() - timedelta(minutes=60)}\n",
    "        ]\n",
    "\n",
    "    def analyze_tweets(self) -> List[Dict]:\n",
    "        tweets = self.get_mock_tweets()\n",
    "        alerts = []\n",
    "\n",
    "        for tweet in tweets:\n",
    "            clean_text = self.preprocess_tweet(tweet['text'])\n",
    "            classification = self.classify_event(clean_text)\n",
    "            if classification['label'] != 'normal' and classification['confidence'] > 0.5:\n",
    "                loc_result = self.extract_location(clean_text)\n",
    "                location_name, coords = loc_result if loc_result else (\"Chennai\", (13.0827, 80.2707))\n",
    "                alerts.append({\n",
    "                    'timestamp': tweet['created_at'],\n",
    "                    'latitude': coords[0],\n",
    "                    'longitude': coords[1],\n",
    "                    'disruption_type': classification['label'],\n",
    "                    'confidence': classification['confidence'],\n",
    "                    'location_name': location_name,\n",
    "                    'description': clean_text,\n",
    "                    'source': 'twitter'\n",
    "                })\n",
    "        return alerts\n",
    "\n",
    "# --------------------- Time-Series Forecasting Stub --------------------- #\n",
    "\n",
    "class TimeSeriesTrafficForecaster:\n",
    "    def __init__(self):\n",
    "        self.hotspots = {\n",
    "            \"nungambakkam - t.nagar\": (13.0418, 80.2341),\n",
    "            \"anna nagar - adyar\": (13.045, 80.215),\n",
    "            \"velachery - omr\": (12.935, 80.224)\n",
    "        }\n",
    "\n",
    "    def analyze_traffic(self) -> List[Dict]:\n",
    "        # Simulated forecasts\n",
    "        alerts = []\n",
    "        for road, coords in self.hotspots.items():\n",
    "            # Simulate low speed condition\n",
    "            predicted_speed = np.random.uniform(4, 9)  # km/h\n",
    "            if predicted_speed < 10:\n",
    "                alerts.append({\n",
    "                    \"timestamp\": datetime.now(),\n",
    "                    \"latitude\": coords[0],\n",
    "                    \"longitude\": coords[1],\n",
    "                    \"disruption_type\": \"low traffic speed\",\n",
    "                    \"forecast_speed\": predicted_speed,\n",
    "                    \"road_segment\": road,\n",
    "                    \"description\": f\"Predicted slow traffic on {road} ({predicted_speed:.1f} km/h)\",\n",
    "                    \"source\": \"forecast\"\n",
    "                })\n",
    "        return alerts\n",
    "\n",
    "# --------------------- Anomaly Detection Model --------------------- #\n",
    "\n",
    "class DeliveryAnomalyDetector:\n",
    "    def __init__(self):\n",
    "        self.isolation_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "        self.scaler = StandardScaler()\n",
    "        self.delivery_routes = {\n",
    "            'D001': {'route_name': 'Nungambakkam to T.Nagar', 'coordinates': [(13.0569, 80.2412), (13.0418, 80.2341)], 'avg_delivery_time': 25},\n",
    "            'D002': {'route_name': 'Anna Nagar to Adyar', 'coordinates': [(13.0850, 80.2101), (13.0067, 80.2206)], 'avg_delivery_time': 35},\n",
    "            'D003': {'route_name': 'Velachery to OMR', 'coordinates': [(12.9816, 80.2209), (12.8956, 80.2267)], 'avg_delivery_time': 30}\n",
    "        }\n",
    "\n",
    "    def generate_mock_data(self) -> pd.DataFrame:\n",
    "        rows = []\n",
    "        delivery_ids = [\"D001\", \"D002\", \"D003\"]\n",
    "        for delivery_id in delivery_ids:\n",
    "            for ts in pd.date_range(\"2025-07-01 10:00\", \"2025-07-01 23:00\", freq=\"H\"):\n",
    "                delay = np.random.normal(loc=5, scale=2)\n",
    "                if np.random.rand() < 0.1:\n",
    "                    delay += np.random.uniform(15, 45)\n",
    "                rows.append([ts, delivery_id, max(0, round(delay, 2))])\n",
    "        return pd.DataFrame(rows, columns=[\"timestamp\", \"delivery_id\", \"delay_minutes\"])\n",
    "\n",
    "    def engineer_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df['hour'] = df['timestamp'].dt.hour\n",
    "        df['delay_deviation'] = df.apply(lambda row: row['delay_minutes'] - self.delivery_routes[row['delivery_id']]['avg_delivery_time'], axis=1)\n",
    "        return df\n",
    "\n",
    "    def detect_anomalies(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = df[['delay_minutes', 'hour', 'delay_deviation']]\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        df['is_anomaly'] = self.isolation_forest.fit_predict(X_scaled)\n",
    "        df['is_anomaly'] = (df['is_anomaly'] == -1).astype(int)\n",
    "        return df[df['is_anomaly'] == 1]\n",
    "\n",
    "    def analyze_delivery_delays(self) -> List[Dict]:\n",
    "        df = self.generate_mock_data()\n",
    "        df = self.engineer_features(df)\n",
    "        anomalies = self.detect_anomalies(df)\n",
    "\n",
    "        alerts = []\n",
    "        for _, row in anomalies.iterrows():\n",
    "            route_info = self.delivery_routes[row['delivery_id']]\n",
    "            for i, coord in enumerate(route_info['coordinates']):\n",
    "                alerts.append({\n",
    "                    \"timestamp\": row['timestamp'],\n",
    "                    \"latitude\": coord[0],\n",
    "                    \"longitude\": coord[1],\n",
    "                    \"disruption_type\": \"delivery delay anomaly\",\n",
    "                    \"delay_minutes\": row['delay_minutes'],\n",
    "                    \"route_name\": route_info['route_name'],\n",
    "                    \"coordinate_type\": \"start\" if i == 0 else \"end\",\n",
    "                    \"description\": f\"Delay anomaly: {row['delay_minutes']} min\",\n",
    "                    \"source\": \"anomaly\"\n",
    "                })\n",
    "        return alerts\n",
    "\n",
    "# --------------------- Main ML Engine --------------------- #\n",
    "\n",
    "def run_combined_ml_engine() -> List[Dict]:\n",
    "    all_alerts = []\n",
    "\n",
    "    # Twitter NLP\n",
    "    try:\n",
    "        nlp_model = TwitterNLPModel()\n",
    "        all_alerts += nlp_model.analyze_tweets()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"NLP model error: {e}\")\n",
    "\n",
    "    # Time-Series Forecasting\n",
    "    try:\n",
    "        traffic_model = TimeSeriesTrafficForecaster()\n",
    "        all_alerts += traffic_model.analyze_traffic()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Forecast model error: {e}\")\n",
    "\n",
    "    # Anomaly Detection\n",
    "    try:\n",
    "        anomaly_model = DeliveryAnomalyDetector()\n",
    "        all_alerts += anomaly_model.analyze_delivery_delays()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Anomaly model error: {e}\")\n",
    "\n",
    "    # Save to JSON\n",
    "    with open(\"combined_disruption_alerts.json\", \"w\") as f:\n",
    "        json.dump(all_alerts, f, indent=2, default=str)\n",
    "\n",
    "    print(f\"\\nâœ… Combined alerts saved to 'combined_disruption_alerts.json'\")\n",
    "    return all_alerts\n",
    "\n",
    "# --------------------- Run It --------------------- #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    alerts = run_combined_ml_engine()\n",
    "    for a in alerts[:5]:\n",
    "        print(f\"\\nðŸš¨ {a['disruption_type'].title()} @ ({a['latitude']}, {a['longitude']})\\n  â†’ {a['description']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d46cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
